---
title: "Virtual Resume"
---

# Career Experience

## Parker, Smith & Feek

::: columns
::: {.column width="65%"}

### Benefits Data Analyst
#### 2018 - 2023

My first career experience after finishing my undergraduate degree. During this time, I provided analytical insights and financial reports to multiple clients, all while building a network and learning about professionalism.

**Key Tasks and Accomplishments:**

- Updated and monitored financial and health data used in conducting analyses to identify trends, discrepancies, 
and produce recommendations.
- Leveraged findings during the renewal process and utilized data to negotiate premiums with insurance carriers.
- Communicated key metrics and statistics by preparing and presenting periodic reports for clients.
- Automated internal tasks by creating VBA macros and scripts.

Small scale automation projects during my time as a Benefits Data Analyst helped me start to develop my programming repertoire, and a few of the generic models I built prior to implementing in my work can be found [here](/posts/all/vba-projects/index.qmd).
:::

::: {.column width="5%"}
:::

::: {.column width="30%"}
![](images/psf_logo.png)
:::
:::

# Education

## Master of Science, Data Science (MSDS)

::: columns
::: {.column width="30%"}

![](images/cu_boulder.png)
:::

::: {.column width="5%"}
:::

::: {.column width="30%"}

### University of Colorado. Boulder
#### 2023 - Current
#### Expected Graduation 2025


**Key Accolades**

- [Bias in Facial Classification Machine Learning Models](/posts/all/bias-in-ml-models/index.qmd)
:::
:::

## Bachelor of Arts in Mathematics, Minor in Applied Mathematics

::: columns
::: {.column width="30%"}

![](images/uw_seattle.png)
:::

::: {.column width="5%"}
:::

::: {.column width="30%"}

### University of Washington, Seattle
#### 2013 - 2017
#### Graduated 2017


**Key Accolades**

- Alpha Sigma Phi Fraternity
- UW Actuary Club
  - Co-President
  - Communications Chair
:::
:::

# Certifications

## Data Science Nanodegree

::: columns
::: {.column width="65%"}

### Udacity
#### 2023

Gained real-world data science experience with curriculum and projects designed by industry experts.

An online certificate of completion can be found [here](https://graduation.udacity.com/confirm/e/4e26e3fc-c452-11ec-a92d-ffb035cf7275).

**Knowledge Gained:**

- Used Python across many data science topics, while utilizing Git to document the progress.
- Object Oriented Programming and Web Development.
- ETL Pipelines, Natural Language Processing, and Machine Learning Pipelines.
- A/B Testing and Recommendation Engines.

**Projects Completed:**

- [Capstone: Natural Language Processing with Articles](/posts/all/nlp-articles/index.qmd)
- [Disaster Response Dashboard](/posts/all/disaster-response-dash/index.qmd)
- [Basic Flashcards Applications](/posts/all/flashcards-basic/index.qmd)
- [Emergency Calls](/posts/all/emergency-calls/index.qmd)
:::

::: {.column width="5%"}
:::

::: {.column width="30%"}
![](images/Udacity.png)
:::
:::

## Expressway to Data Science: R Programming and Tidyverse

::: columns
::: {.column width="65%"}

### Coursera
#### 2023

A specialization in R programming earned upon the completion of 3 courses:

- Introduction to R Programming and Tidyverse
- Data Analysis with Tidyverse
- R Programming and Tidyverse Capstone Project

An online certificate of completion can be found [here](https://www.coursera.org/account/accomplishments/specialization/WF8N8PFDWFCN).

**Knowledge Gained:**

- Use R and the tidyverse to import data from external repositories and local CSV files.
- Clean and transform data for analysis, construct visualizations.
- Document and reflect on analyses using RMarkdown.

**Projects Completed:**

- [Capstone: COVID-19 Analysis](/posts/all/covid-analysis/index.qmd)
:::

::: {.column width="5%"}
:::

::: {.column width="30%"}
![](images/r_specialization.png)
:::
:::

# Technical Proficencies

::: columns
::: {.column width="15%"}
### Excel
:::

::: {.column width="5%"}
:::

::: {.column width="80%"}
<details>
The main analysis tool of my first position after my undergraduate degree, I used Excel almost daily for 5 years for real world analyses. This encompassed the exploratory, the explanatory, and anything visual; I was tasked with creating PowerPoint presentations, PDFs, and dashboards all driven by Excel.

*My [Downloadable Resume](resume.qmd) was even created using Excel.*
</details>
:::
:::

---

::: columns
::: {.column width="15%"}
### SQL
:::

::: {.column width="5%"}
:::

::: {.column width="80%"}
<details>
I've taken several courses featuring SQL, and have used SQL and SQLAlchemy as the database tool for projects such as the [Disaster Response Dashboard](/posts/featured/disaster-response-dash/index.qmd).
</details>
:::
:::

---

::: columns
::: {.column width="15%"}
### VBA
:::

::: {.column width="5%"}
:::

::: {.column width="80%"}
<details>
Because I was tasked with primarily using Excel in my first position after my undergraduate degree, there were some disadvantages that aren't inherent in tools such as Python. To combat this, I learned VBA and implemented several macros and even completed entire projects aimed at increasing efficiency and reducing errors.

Although not as user friendly as a language like Python, using VBA shined a light on how processes surrounding data pipelines could look, and ultimately gave me a nudge to continue down the data science pathway.

Please see [VBA Projects](/posts/all/vba-projects/index.qmd) for some examples.
</details>
:::
:::

---

::: columns
::: {.column width="15%"}
### Git & GitHub
:::

::: {.column width="5%"}
:::

::: {.column width="80%"}
<details>
I use Git and GitHub for *almost* every single project now. From manually copying and pasting documentation for my first few projects ([Rudimentary Python Projects](/posts/all/rud-python-projects/index.qmd), [VBA Projects](/posts/all/vba-projects/index.qmd)), learning command line and proper project documentation during the **Data Science Nanodegree** certificate listed above, to creating this website heavily reliant on Git, I've gained great confidence in the tool.
</details>
:::
:::

---

::: columns
::: {.column width="15%"}
### Python
:::

::: {.column width="5%"}
:::

::: {.column width="80%"}
<details>
A staple of modern programming, Python is my preferred language.

- Basic Functions
- Object Oriented Programming
- NumPy
- Pandas
- Visualizations
  - matplotlib
  - seaborn
  - plotly
- Jupyter notebooks
  - interactivty with ipywidgets
- sklearn
- NLTK

I'm quite familiar with each of these concepts and libraries, and I'm quickly becoming proficient at implementing them in a host of scenarios.
</details>
:::
:::

---

::: columns
::: {.column width="15%"}
### LaTeX
:::

::: {.column width="5%"}
:::

::: {.column width="80%"}
<details>
After working for a few years and deciding to go deeper into data science, I needed to brush up on my math skills. Something that I neglected from my undergraduate years was keeping my math notes well organized and accessible. This time around, I decided that I was going to create a system that I could return to when needed.

Learning LaTeX has actually proven to be indispensable during my time back in my Master's of Data Science program.
</details>
:::
:::

---

::: columns
::: {.column width="15%"}
### R
:::

::: {.column width="5%"}
:::

::: {.column width="80%"}
<details>
Probably second to Python as my preferred language, I've used R extensively in my statistics courses. I was surprised to find it almost as capable as Python.

Part of completing the **Expressway to Data Science: R Programming and Tidyverse** certificate listed above was successfully passing the capstone, for which I did the [COVID Analysis](/posts/all/covid-analysis/index.qmd) project.

Additionally, the project [Bias in Facial Classification ML Models](/posts/featured/bias-in-ml-models/index.qmd) was done almost exclusively in R. Although a group effort, I was responsible for building the Shiny dashboard seen in [this section](https://cuboulder-ds.github.io/5301-5000-Final-Report/data.html). The standalone app is hosted on *shinyapps server*, available [here](https://carlklein.shinyapps.io/5000-final/).
</details>
:::
:::

---

::: columns
::: {.column width="15%"}
### Quarto
:::

::: {.column width="5%"}
:::

::: {.column width="80%"}
<details>
I was first introduced to Quarto during the project [Bias in Facial Classification ML Models](/posts/featured/bias-in-ml-models/index.qmd). since then, I've recognized the potential in it's utility. To name a few instances:

- Academic Papers
- Interactive Dashboards
- Websites

In fact, I've created this website using Quarto.
</details>
:::
:::

<!--
## Excel

The main analysis tool of my first position after my undergraduate degree, I used Excel almost daily for 5 years for real world analyses. This encompassed the exploratory, the explanatory, and anything visual; I was tasked with creating PowerPoint presentations, PDFs, and dashboards all driven by Excel.

*My [Downloadable Resume](resume.qmd) was even created using Excel.*


## SQL

I've taken several courses featuring SQL, and have used SQL and SQLAlchemy as the database tool for projects such as the [Disaster Response Dashboard](/posts/featured/disaster-response-dash/index.qmd).


## VBA

Because I was tasked with primarily using Excel in my first position after my undergraduate degree, there were some disadvantages that aren't inherent in tools such as Python. To combat this, I learned VBA and implemented several macros and even completed entire projects aimed at increasing efficiency and reducing errors.

Although not as user friendly as a language like Python, using VBA shined a light on how processes surrounding data pipelines could look, and ultimately gave me a nudge to continue down the data science pathway.

Please see [VBA Projects](/posts/all/vba-projects/index.qmd) for some examples.

## Git / GitHub

I use Git and GitHub for *almost* every single project now. From manually copying and pasting documentation for my first few projects ([Rudimentary Python Projects](/posts/all/rud-python-projects/index.qmd), [VBA Projects](/posts/all/vba-projects/index.qmd)), learning command line and proper project documentation during the **Data Science Nanodegree** certificate listed above, to creating this website heavily reliant on Git, I've gained great confidence in the tool.


## Python

A staple of modern programming, Python is my preferred language.

- Basic Functions
- Object Oriented Programming
- NumPy
- Pandas
- Visualizations
  - matplotlib
  - seaborn
  - plotly
- Jupyter notebooks
  - interactivty with ipywidgets
- sklearn
- NLTK

I'm quite familiar with each of these concepts and libraries, and I'm quickly becoming proficient at implementing them in a host of scenarios.


## LaTeX

After working for a few years and deciding to go deeper into data science, I needed to brush up on my math skills. Something that I neglected from my undergraduate years was keeping my math notes well organized and accessible. This time around, I decided that I was going to create a system that I could return to when needed.

Learning LaTeX has actually proven to be indispensable during my time back in my Master's of Data Science program.


## R

Probably second to Python as my preferred language, I've used R extensively in my statistics courses. I was surprised to find it almost as capable as Python.

Part of completing the **Expressway to Data Science: R Programming and Tidyverse** certificate listed above was successfully passing the capstone, for which I did the [COVID Analysis](/posts/all/covid-analysis/index.qmd) project.

Additionally, the project [Bias in Facial Classification ML Models](/posts/featured/bias-in-ml-models/index.qmd) was done almost exclusively in R. Although a group effort, I was responsible for building the Shiny dashboard seen in [this section](https://cuboulder-ds.github.io/5301-5000-Final-Report/data.html). The standalone app is hosted on *shinyapps server*, available [here](https://carlklein.shinyapps.io/5000-final/).


## Quarto

I was first introduced to Quarto during the project [Bias in Facial Classification ML Models](/posts/featured/bias-in-ml-models/index.qmd). since then, I've recognized the potential in it's utility. To name a few instances:

- Academic Papers
- Interactive Dashboards
- Websites

In fact, I've created this website using Quarto.
-->
